<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Competing Risks on Paul C. Lambert</title>
    <link>/tags/competing-risks/</link>
    <description>Recent content in Competing Risks on Paul C. Lambert</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Paul C Lambert</copyright>
    <lastBuildDate>Sun, 27 Aug 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/competing-risks/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>stcrprep - computational benefits</title>
      <link>/software/stcrprep/computational_benefits/</link>
      <pubDate>Sun, 27 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/software/stcrprep/computational_benefits/</guid>
      <description>&lt;p&gt;When using &lt;code&gt;stcrprep&lt;/code&gt; there are some computational benefits when compared to using Stata&amp;rsquo;s inbuilt &lt;code&gt;stcrreg&lt;/code&gt;. One reason for this is that everytime you fit a model using &lt;code&gt;stcrreg&lt;/code&gt; you the probability of censoring weights are calculated and the data must be expanded (in the background) when maximising the likelihood. When using &lt;code&gt;stcrprep&lt;/code&gt; you only need to do this once.&lt;/p&gt;

&lt;p&gt;I have run some timings. If I fit a simple model to the embt1 data with risk score as the only covariate (2 dummy variables) then these are the timings no my current work laptop (Intel i5 - running Stata 15 MP2).&lt;/p&gt;

&lt;p&gt;First I load and &lt;code&gt;stset&lt;/code&gt; the data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;. use https://www.pclambert.net/data/ebmt1_stata.dta, clear

. stset time, failure(status==1) scale(365.25) id(patid) noshow

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, &lt;code&gt;stcrreg&lt;/code&gt; can be used&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;. timer clear

. timer on 1

. stcrreg i.score, compete(status==2) nolog noshow

Competing-risks regression                       No. of obs       =      1,977
                                                 No. of subjects  =      1,977
Failure event  : status == 1                     No. failed       =        456
Competing event: status == 2                     No. competing    =        685
                                                 No. censored     =        836

                                                 Wald chi2(2)     =       9.87
Log pseudolikelihood = -3333.3217                Prob &amp;gt; chi2      =     0.0072

                              (Std. Err. adjusted for 1,977 clusters in patid)
------------------------------------------------------------------------------
             |               Robust
          _t |        SHR   Std. Err.      z    P&amp;gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
       score |
Medium risk  |   1.271221   .1554323     1.96   0.050     1.000333    1.615465
  High risk  |   1.769853   .3238535     3.12   0.002     1.236465    2.533337
------------------------------------------------------------------------------

. timer off 1

. timer list
   1:     15.35 /        1 =      15.3500

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This takes 15.4 seconds to fit.&lt;/p&gt;

&lt;p&gt;I now reload and &lt;code&gt;stset&lt;/code&gt; the data, but this time declaring both &lt;code&gt;status=1&lt;/code&gt; and &lt;code&gt;status=2&lt;/code&gt; as events.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;. use https://www.pclambert.net/data/ebmt1_stata.dta, clear

. stset time, failure(status==1,2) scale(365.25) id(patid)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can now run &lt;code&gt;stcrprep&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;. timer on 2

. stcrprep, events(status) keep(score) trans(1)   

. timer off 2

. timer list 2
   2:      4.39 /        1 =       4.3910

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This takes  4.4 seconds to run. However, this only restructures the data and calculates the weights. To fit the model, we first generate the event indicator and  use &lt;code&gt;stset&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;. gen      event = status == failcode

. stset tstop [iw=weight_c], failure(event) enter(tstart) 

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We use &lt;code&gt;stcox&lt;/code&gt; to fit the model.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;. timer on 3

. stcox i.score

         failure _d:  event
   analysis time _t:  tstop
  enter on or after:  time tstart
             weight:  [iweight=weight_c]

Iteration 0:   log likelihood = -3338.1244
Iteration 1:   log likelihood = -3333.4173
Iteration 2:   log likelihood = -3333.3113
Iteration 3:   log likelihood = -3333.3112
Refining estimates:
Iteration 0:   log likelihood = -3333.3112

Cox regression -- Breslow method for ties

No. of subjects =       72,880                  Number of obs    =      72,880
No. of failures =          456
Time at risk    =   6026.27434
                                                LR chi2(2)       =        9.63
Log likelihood  =   -3333.3112                  Prob &amp;gt; chi2      =      0.0081

------------------------------------------------------------------------------
          _t | Haz. Ratio   Std. Err.      z    P&amp;gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
       score |
Medium risk  |   1.271235   .1593392     1.91   0.056     .9943389    1.625238
  High risk  |   1.769899   .3219273     3.14   0.002     1.239148     2.52798
------------------------------------------------------------------------------

. timer off 3

. timer list
   1:     15.35 /        1 =      15.3500
   2:      4.39 /        1 =       4.3910
   3:      1.09 /        1 =       1.0930

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This takes  1.1 seconds to run giving a combined total of  5.5 seconds. What is important is that if we want to fit other models (including other covariates etc), then we do not need to run &lt;code&gt;stcrprep&lt;/code&gt; again.&lt;/p&gt;

&lt;p&gt;To assess the time on larger data I have expanded the data by 20 times and added a small random number to each time, so that there are no ties. I used the following code.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;expand 20
replace time = time + runiform()*0.0001
replace patid = _n
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This leads to 19,770 indviduals in the analysis. The fact that there are no ties is perhaps a little unrealistic in a dataset this size, but this is still a usefull assessment of computational speed. The same analysis as above on this larger dataset gave the following times.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;command&lt;/th&gt;
&lt;th&gt;Time&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;stcrreg&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;2066.3 seconds&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;stcrprep&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;890.2 seconds&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;stcox&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;46.1 seconds&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;I think this really highlights the benfits of restructuring the data and using &lt;code&gt;stcox&lt;/code&gt; in terms of computational time. Unless there is need to recalculate the probability of censoring weights, there is no need to do this every time you fit a model. Thus, in this case an &lt;code&gt;stcrreg&lt;/code&gt; model takes almost 35 minutes, whilst the same model using &lt;code&gt;stcox&lt;/code&gt; after using &lt;code&gt;stcrprep&lt;/code&gt;takes only 46 seconds.&lt;/p&gt;

&lt;p&gt;It is worthwhile noting that Stata&amp;rsquo;s implementation of Fine and Grays proportional subhazards model using &lt;code&gt;stcrreg&lt;/code&gt; seems particularly slow. If I fit the model in R using &lt;code&gt;crr&lt;/code&gt; the model fitted to the expanded data it only takes 370 seconds compared to 2066 in Stata.&lt;/p&gt;

&lt;p&gt;There are other benefits with using &lt;code&gt;stcox&lt;/code&gt; to fit the subhazards model, mainly because we can now use many of the other commands and extensions associated with &lt;code&gt;stcox&lt;/code&gt;. I will discuss these in other tutorials.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>stcrprep</title>
      <link>/software/stcrprep/</link>
      <pubDate>Mon, 21 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/software/stcrprep/</guid>
      <description>

&lt;p&gt;stcrprep prepares data for estimating and modelling cause-specific cumulative incidence functions using time-dependent weights. Once the data has been prepared and the weights incorporated using &lt;code&gt;stset&lt;/code&gt; it is possible to obtain a graph of the non-parametric estimates of the cause-specific cumulative incidence function using &lt;code&gt;sts graph&lt;/code&gt;.  In addition a model that estimates subhazard ratios (equivalent to the Fine and Gray model) can be fitted using &lt;code&gt;stcox&lt;/code&gt;. It is also possible to fit parametric models to directly estimate the cause-specific CIF (my main reason for developing the command).&lt;/p&gt;

&lt;p&gt;Below are some simple examples of using &lt;code&gt;stcrprep&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;examples&#34;&gt;Examples&lt;/h2&gt;

&lt;h3 id=&#34;non-and-semi-parametric-methods&#34;&gt;Non and semi parametric methods&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/software/stcrprep/nonparametriccif/&#34;&gt;Using sts graph for cause-specific CIFs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Using &lt;code&gt;stcox&lt;/code&gt; instead of &lt;code&gt;stcrreg&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/software/stcrprep/computational_benefits/&#34;&gt;Computational benefits of using &lt;code&gt;stcrprep&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Schoenfeld residuals&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;parametric-models&#34;&gt;Parametric models&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Using &lt;code&gt;stpm2&lt;/code&gt; to model the cause-specific CIF&lt;/li&gt;
&lt;li&gt;Alternative link functions.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>stcrprep - non parametric cause-specific CIFs</title>
      <link>/software/stcrprep/nonparametriccif/</link>
      <pubDate>Sun, 06 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/software/stcrprep/nonparametriccif/</guid>
      <description>

&lt;p&gt;I will use the same data set I use in the &lt;em&gt;Stata Journal&lt;/em&gt; &lt;a href=&#34;http://www.stata-journal.com/article.html?article=st0471&#34;&gt;article&lt;/a&gt; on &lt;code&gt;stcrprep&lt;/code&gt;.
This comprises of 1977 patients from the European Blood and Marrow Transplantation (EBMT) registry who received an allogeneic bone
marrow transplantation. Time is measured in days from transplantation to either relapse
or death. There is only one covariate of interest, the EBMT risk score, which has been
categorized into 3 groups (low, medium and high risk). The data is available as part of
the mstate R package (de Wreede et al. 2011).&lt;/p&gt;

&lt;p&gt;First I load the data,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;. use http://www.pclambert.net/data/ebmt1_stata.dta, clear
(Written by R.              )

. tab status

     status |      Freq.     Percent        Cum.
------------+-----------------------------------
   censored |        836       42.29       42.29
    relapse |        456       23.07       65.35
       died |        685       34.65      100.00
------------+-----------------------------------
      Total |      1,977      100.00

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The tabulation shows that of the 1,977 subjects, 836 were censored, 456 had a relapse and 686 had a death before relapse. Now we can &lt;code&gt;stset&lt;/code&gt; the data declaring both relapse and death as an event in the &lt;code&gt;failure()&lt;/code&gt; option.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;. stset time, failure(status==1,2) scale(365.25) id(patid)

                id:  patid
     failure event:  status == 1 2
obs. time interval:  (time[_n-1], time]
 exit on or before:  failure
    t for analysis:  time/365.25

------------------------------------------------------------------------------
      1,977  total observations
          0  exclusions
------------------------------------------------------------------------------
      1,977  observations remaining, representing
      1,977  subjects
      1,141  failures in single-failure-per-subject data
  3,796.057  total analysis time at risk and under observation
                                                at risk from t =         0
                                     earliest observed entry t =         0
                                          last observed exit t =  8.454483

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In order to show how &lt;code&gt;stcrprep&lt;/code&gt; expands the data and calculates the probability of censoring weights for those with a competing event, I will list the data of a single individual before and after using &lt;code&gt;stcrprep&lt;/code&gt;. The listing is for subject 17 (&lt;code&gt;patid==17&lt;/code&gt;).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;. list patid status _t0 _t _d if patid==17, noobs

  +---------------------------------------+
  | patid   status   _t0          _t   _d |
  |---------------------------------------|
  |    17     died     0   2.2888433    1 |
  +---------------------------------------+

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This subject died after 2.29 years and  before using &lt;code&gt;stcrprep&lt;/code&gt; has just has one row of
data.&lt;/p&gt;

&lt;p&gt;Next I use &lt;code&gt;stcrprep&lt;/code&gt; to restructure the data. The &lt;code&gt;events()&lt;/code&gt; option requires the variable defining all possible events and the censored value. The &lt;code&gt;trans()&lt;/code&gt; option gives the transitions of the events of interest; here we
are interested in the transitions to both relapse(&lt;code&gt;status=1&lt;/code&gt;) and death (&lt;code&gt;status=2&lt;/code&gt;); this is actually the default, but is shown here for clarity. The &lt;code&gt;keep()&lt;/code&gt; option is used to list variables to retain in the expanded data; usually any covariates that will be later analysed are included here. The &lt;code&gt;byg()&lt;/code&gt; option requests the censoring distribution to be estimated separately for the given groups. Since we are first going to obtain a separate
non-parametric estimate of the cause-specific CIF in each group, the byg() option will estimate the censoring distribution separately in each group.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;. stcrprep, events(status) keep(score) trans(1 2) byg(score)

. di &amp;quot;There are &amp;quot; _N &amp;quot; observations&amp;quot;
There are 70262 observations

. format tstart %6.5f                                                                     

. format tstop %6.5f

. format weight_c %6.5f

. list failcode patid status tstart tstop weight_c weight_t status if patid==17, ///
&amp;gt;          sepby(failcode) noobs 

  +------------------------------------------------------------------------------+
  | failcode   patid   status    tstart     tstop   weight_c   weight_t   status |
  |------------------------------------------------------------------------------|
  |  relapse      17     died   0.00000   2.28884    1.00000          1     died |
  |  relapse      17     died   2.28884   2.31622    0.99000          1     died |
  |  relapse      17     died   2.31622   2.32717    0.98497          1     died |
  |  relapse      17     died   2.32717   2.36003    0.97992          1     died |
  |  relapse      17     died   2.36003   2.55441    0.91392          1     died |
  |  relapse      17     died   2.55441   2.65845    0.89843          1     died |
  |  relapse      17     died   2.65845   2.89938    0.85142          1     died |
  |  relapse      17     died   2.89938   3.02806    0.80937          1     died |
  |  relapse      17     died   3.02806   3.18960    0.76176          1     died |
  |  relapse      17     died   3.18960   3.26626    0.74578          1     died |
  |  relapse      17     died   3.26626   3.62765    0.63847          1     died |
  |  relapse      17     died   3.62765   3.89870    0.59519          1     died |
  |  relapse      17     died   3.89870   3.97536    0.57881          1     died |
  |  relapse      17     died   3.97536   4.10951    0.55124          1     died |
  |  relapse      17     died   4.10951   4.39425    0.51163          1     died |
  |  relapse      17     died   4.39425   4.50103    0.47714          1     died |
  |  relapse      17     died   4.50103   4.69815    0.45968          1     died |
  |  relapse      17     died   4.69815   5.08419    0.37101          1     died |
  |  relapse      17     died   5.08419   5.22656    0.32235          1     died |
  |  relapse      17     died   5.22656   5.33607    0.30995          1     died |
  |  relapse      17     died   5.33607   5.97673    0.22772          1     died |
  |  relapse      17     died   5.97673   6.27515    0.20170          1     died |
  |------------------------------------------------------------------------------|
  |     died      17     died   0.00000   2.28884    1.00000          1     died |
  +------------------------------------------------------------------------------+

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After using &lt;code&gt;stcrprep&lt;/code&gt; the number of rows has increased from 1977 to 70262. The rows have been divided based on the failure of the newly created variable &lt;code&gt;failcode&lt;/code&gt;. This variable will be used to fit different models depending on the event of interest. The variables &lt;code&gt;patid&lt;/code&gt; and &lt;code&gt;status&lt;/code&gt; are the same as in the non expanded data. The variables &lt;code&gt;tstart&lt;/code&gt; and &lt;code&gt;tstop&lt;/code&gt; give the times an individual starts and stops being at risk. They
change within an individual when their weight, defined by variable &lt;code&gt;weight_c&lt;/code&gt;, changes value. The &lt;code&gt;weight_t&lt;/code&gt; gives the weights when there is left trunction. As there is no left truncation in this data, it takes the value 1 for all subjects at all times.&lt;/p&gt;

&lt;p&gt;When &lt;code&gt;failcode==1&lt;/code&gt; this corresponds to when a relapse is the event of interest. As
the subject with &lt;code&gt;patid==17&lt;/code&gt; died after 2.29 years (i.e. had a competing event), they
are initially at risk until this time and they should receive a weight of 1 in the analysis.
After their death they are still kept in the risk set, but their weight decreases. The
decrease is based on the conditional probability of being censored which is estimated
using a non-parametric (Kaplan-Meier) estimate of the censoring distribution. The
weights only change at times when there is a failure for the event of interest and the
value of censoring distribution has changed.&lt;/p&gt;

&lt;p&gt;When &lt;code&gt;failcode==2&lt;/code&gt; this corresponds to when death is the event of interest. Since
this patient experienced the event of interest (i.e. they died) rather than the competing event, they only require one row of data.&lt;/p&gt;

&lt;p&gt;We can use &lt;code&gt;sts graph&lt;/code&gt; to give a plot of the cause-specific CIF. We first need to &lt;code&gt;stset&lt;/code&gt;
the data utilizing the information on the weights contained in variable &lt;code&gt;weights_c&lt;/code&gt; by
specifiying &lt;code&gt;iweights&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;. gen event = status == failcode

. stset tstop [iw=weight_c], failure(event) enter(tstart) noshow                                          // stset using weights

     failure event:  event != 0 &amp;amp; event &amp;lt; .
obs. time interval:  (0, tstop]
 enter on or after:  time tstart
 exit on or before:  failure
            weight:  [iweight=weight_c]

------------------------------------------------------------------------------
     70,262  total observations
          0  exclusions
------------------------------------------------------------------------------
     70,262  observations remaining, representing
      1,141  failures in single-record/single-failure data
 13,820.402  total analysis time at risk and under observation
                                                at risk from t =         0
                                     earliest observed entry t =         0
                                          last observed exit t =  8.454483

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We first create the variable, &lt;code&gt;event&lt;/code&gt;. This is defined as 1 if the event of interest occurs
and zero otherwise. As we have split time data, we need to give information on the start
time (&lt;code&gt;tstart&lt;/code&gt;) and stop time (&lt;code&gt;tstop&lt;/code&gt;) of each row of data.
We use &lt;code&gt;sts graph&lt;/code&gt; in the usual way, but use the failure option as we are interested
in the probability of relapse as opposed to the probability of not having a relapse (which
includes the probability of death). For example, the cause-specific CIF for relapse can
be plotted as follows,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;. sts graph if failcode==1, by(score) failure ///
&amp;gt;         ytitle(&amp;quot;Probability of Relapse&amp;quot;) ///
&amp;gt;         xtitle(&amp;quot;Years since transplanation&amp;quot;) ///
&amp;gt;         ylabel(0(0.1)0.5, angle(h) format(%3.1f)) ///
&amp;gt;         legend(order(1 &amp;quot;Low Risk&amp;quot; 2 &amp;quot;Medium Risk&amp;quot; 3 &amp;quot;High Risk&amp;quot;) ///
&amp;gt;         cols(1) ring(0) pos(5)) ///
&amp;gt;         scheme(sj) name(cif_relapse, replace)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;/statasvg/stcrprep_cif1.svg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note that the lines are extended to the maximum censoring time in each group, rather than the maximum event time.
Alternatively, &lt;code&gt;sts gen&lt;/code&gt; can be used to generate the cause-specific CIF and this can be
plotted with appropriate if statements to control the maximum follow-up time for each line.&lt;/p&gt;

&lt;p&gt;It is also possible to list the CIF at specific time points using &lt;code&gt;sts list&lt;/code&gt;. For example, the cause-specific CIF at 1 and 5 years by risk group and for each cause can be obtained as follows,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;. sts list, at(1 5) failure by(failcode score)    

              Beg.                      Failure       Std.
    Time     Total     Fail             Function     Error     [95% Conf. Int.]
-------------------------------------------------------------------------------
relapse Low risk 
       1   348.001       38              0.0959    0.0148     0.0707    0.1295
       5   94.7875       36              0.2268    0.0250     0.1821    0.2805
relapse Medium risk 
       1   1125.93      225              0.1636    0.0100     0.1451    0.1843
       5   268.081      100              0.2594    0.0131     0.2347    0.2861
relapse High risk 
       1   116.387       39              0.2417    0.0338     0.1827    0.3156
       5         6       10              0.3306    0.0410     0.2574    0.4181
died Low risk 
       1   306.828       81              0.2032    0.0202     0.1669    0.2462
       5   94.9111       10              0.2368    0.0223     0.1964    0.2839
died Medium risk 
       1   915.771      441              0.3189    0.0126     0.2950    0.3442
       5   209.617       70              0.3829    0.0137     0.3566    0.4104
died High risk 
       1   84.7723       73              0.4494    0.0392     0.3764    0.5296
       5         6        7              0.5160    0.0452     0.4310    0.6071
-------------------------------------------------------------------------------
Note: Failure function is calculated over full data and evaluated at indicated
      times; it is not calculated from aggregates shown at left.

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, we can test for differences in the cause-specific CIF using &lt;code&gt;sts test&lt;/code&gt;. Note that is slightly different to the modified log rank test defined by Gray (1988).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-stata&#34;&gt;. sts test score if failcode==1


Log-rank test for equality of survivor functions

            |   Events         Events
score       |  observed       expected
------------+-------------------------
Low risk    |        79          99.64
Medium risk |       328         324.33
High risk   |        49          32.04
------------+-------------------------
Total       |       456         456.00

                  chi2(2) =      13.37
                  Pr&amp;gt;chi2 =     0.0012

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;p&gt;de Wreede, L.; Fiocco, M. &amp;amp; Putter, H. &lt;code&gt;mstate&lt;/code&gt;: An R package for the analysis of competing risks and multi-state models. &lt;em&gt;Journal of Statistical Software&lt;/em&gt; 2011;&lt;strong&gt;38&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Gray, R. A class of K-sample tests for comparing the cumulative incidence of a competing risk. &lt;em&gt;The Annals of Statistics&lt;/em&gt; 1988;&lt;strong&gt;16&lt;/strong&gt;:1141-1154.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
